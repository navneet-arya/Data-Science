{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Load Packages\nimport sys # access to system parameters https://docs.python.org/3/library/sys.html\nprint(\"Python Version: {}\".format(sys.version))\n\nimport pandas as pd # Collection of functions for data processing and analysis modeled after R dataframes with Sql\nprint(\"Pandas Version: {}\".format(pd.__version__))\n\nimport matplotlib\nprint(\"Matplotlib version: {}\".format(matplotlib.__version__))\n\nimport numpy as np\nprint(\"Numpy Version: {}\".format(np.__version__))\n\nimport scipy as sp # For scientific computing and advance mathematics\nprint(\"Scipy version: {}\".format(sp.__version__))\n\nimport IPython\nfrom IPython import display # Pretty printing of dataframes in Jupyter notebook\nprint(\"IPython version: {}\".format(IPython.__version__))\n\nimport sklearn # Collection of ML algo\nprint(\"scikit-learn version: {}\".format(sklearn.__version__))\n\nimport random\nimport time\n\n# ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nprint('-'*50)\n\n# Input data files are available in the \"../input/\" directory.\nfrom subprocess import check_output\nprint(check_output([\"ls\",\"../input/titanic\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Common model Algo\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes,ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n# Common Model helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\n# Visualiztion\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.pylab as pylab\nimport seaborn as sns\nfrom pandas.plotting import scatter_matrix\n\n# Configure Visualization Defaults\n# %matplotlib inline = show plots in Jupyter notebook browser\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set_style('white')\npylab.rcParams['figure.figsize']=12,8","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_raw = pd.read_csv('../input/titanic/train.csv')\ndata_val = pd.read_csv('../input/titanic/test.csv')\n\n#however passing by reference is convenient, because we can clean both datasets at once\ndata1 = data_raw.copy(deep=True)\ndata_cleaner = [data1, data_val]\n\n# preview data\nprint(data_raw.info())\ndata_raw.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\nprint('Train columns with null values:\\n',data1.isnull().sum())\nprint('='*30)\n\nprint('Test/Validation columns with null values:\\n',data_val.isnull().sum())\nprint('='*30)\n\ndata_raw.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###The 4 C's of Data Cleaning: Correcting, Completing, Creating, and Converting\n###COMPLETING: Complete or delete missing values in train and test/validation dataset\nfor dataset in data_cleaner:\n    # complete the missing age with median\n    dataset['Age'].fillna(dataset['Age'].median(),inplace=True)\n    \n    # complete embarked with mode\n    dataset['Embarked'].fillna(dataset['Embarked'].mode()[0],inplace=True)\n    \n    # complete missing fare with median\n    dataset['Fare'].fillna(dataset['Fare'].median(),inplace=True)\n\n# Delete the canbin feature/columns and others previously stated to exclude in train dataset\ndrop_column = ['PassengerId','Cabin','Ticket']\ndata1.drop(drop_column,axis=1,inplace=True)\n\nprint(data1.isnull().sum())\nprint('='*30)\nprint(data_val.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###CREATE: Feature Engineering for train and test/validation dataset\nfor dataset in data_cleaner:\n    #Discrete variable\n    dataset['FamilySize']=dataset['SibSp']+dataset['Parch']+1\n    \n    dataset['IsAlone']=1 #initialize to yes/1 is Alone\n    dataset['IsAlone'].loc[dataset['FamilySize']>1]=0 #update to no/0 if family size is greate than 1\n    \n    dataset['Title']=dataset['Name'].str.split(\",\",expand=True)[1].str.split(\".\",expand=True)[0]\n    \n    #Fare Bins/Buckets using qcut or frquency\n    dataset['FareBin'] = pd.qcut(dataset['Fare'],4)\n    \n    #Age Bins/Buckets using cut or value\n    dataset['AgeBin'] = pd.cut(dataset['Age'].astype(int),5)\n\n\n#Cleanup rare title names\n#print(data1['Title'].value_counts())\nstat_min=10\ntitle_names = (data1['Title'].value_counts()<stat_min) #This will create a true false series with title name as index\n\n#apply and lambda functions are quick and dirty code to find and replace with fewer lines of code\ndata1['Title'] = data1['Title'].apply(lambda x: 'Misc' if title_names.loc[x]==True else x)\nprint(data1['Title'].value_counts())\nprint('='*30)\n\ndata1.info()\ndata_val.info()\ndata1.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert Formats\n# We will convert categorical data to dummy variables for mathematical analysis.\n\n##CONVERT: convert obj to category using LabelEncoder for train and test/validation dataset\n\n#code categorical data\nlabel = LabelEncoder()\nfor dataset in data_cleaner:\n    dataset['Sex_Code'] = label.fit_transform(dataset['Sex'])\n    dataset['Embarked_Code'] = label.fit_transform(dataset['Embarked'])\n    dataset['Title_Code'] = label.fit_transform(dataset['Title'])\n    dataset['AgeBin_Code'] = label.fit_transform(dataset['AgeBin'])\n    dataset['FareBin_Code'] = label.fit_transform(dataset['FareBin'])\n\n#define y variable aka target/outcome\nTarget = ['Survived']\n\n#define x variable for original features aka feature selection\ndata1_x=['Sex','Pclass','Embarked','Title','SibSp','Parch','Age','Fare','FamilySize','IsAlone'] #Pretty name/values for charts\ndata1_x_calc=['Sex_Code','Pclass','Embarked_Code','Title_Code','SibSp','Parch','Age','Fare']\ndata1_xy = Target + data1_x\nprint('Original X Y: ',data1_xy,'\\n')\n\n#define x variable for original w/bin features to remove continuous variables\ndata1_x_bin = ['Sex_Code','Pclass','Embarked_Code','Title_Code','FamilySize','AgeBin_Code','FareBin_Code']\ndata1_xy_bin = Target + data1_x_bin\nprint('Bin X Y: ',data1_xy_bin,'\\n')\n\n#define x and y variables for dummy features original\ndata1_dummy = pd.get_dummies(data1[data1_x])\ndata1_x_dummy = data1_dummy.columns.tolist()\ndata1_xy_dummy = Target + data1_x_dummy\nprint('Dummy X Y: ',data1_xy_dummy,'\\n')\n\ndata1_dummy.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Re-checked the clean data again\nprint('Train columns with null values: \\n',data1.isnull().sum())\nprint('='*30)\nprint(data1.info())\nprint('='*30)\n\nprint('Test/Validation columns with null values: \\n',data_val.isnull().sum())\nprint('='*30)\nprint(data_val.info())\nprint('='*30)\ndata_raw.describe(include='all')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split Training and Testing Data\ntrain1_x, test1_x, train1_y, test1_y = model_selection.train_test_split(data1[data1_x_calc], data1[Target], random_state = 0)\ntrain1_x_bin, test1_x_bin, train1_y_bin, test1_y_bin = model_selection.train_test_split(data1[data1_x_bin], data1[Target] , random_state = 0)\ntrain1_x_dummy, test1_x_dummy, train1_y_dummy, test1_y_dummy = model_selection.train_test_split(data1_dummy[data1_x_dummy], data1[Target], random_state = 0)\n\nprint(\"Data1 Shape: {}\".format(data1.shape))\nprint(\"Train1 Shape: {}\".format(train1_x.shape))\nprint(\"Test1 Shape: {}\".format(test1_x.shape))\n\ntrain1_x_bin.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Discrete Variable Correlation by Survival using\nfor x in data1_x:\n    if data1[x].dtype != 'float64':\n        print('Survival Correlation by: ',x)\n        print(data1[[x, Target[0]]].groupby(x, as_index=False).mean())\n        print('='*30,'\\n')\n\n# Using Crosstabs\nprint(pd.crosstab(data1['Title'],data1[Target[0]]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Graph distribution of quantitative data\nplt.figure(figsize=[16,12])\n\nplt.subplot(231)\nplt.boxplot(x=data1['Fare'],showmeans=True,meanline=True)\nplt.title('Fare Boxplot')\nplt.ylabel('Fare ($)')\n\nplt.subplot(232)\nplt.boxplot(data1['Age'], showmeans = True, meanline = True)\nplt.title('Age Boxplot')\nplt.ylabel('Age (Years)')\n\nplt.subplot(233)\nplt.boxplot(data1['FamilySize'], showmeans = True, meanline = True)\nplt.title('Family Size Boxplot')\nplt.ylabel('Family Size (#)')\n\nplt.subplot(234)\nplt.hist(x = [data1[data1['Survived']==1]['Fare'], data1[data1['Survived']==0]['Fare']], \n         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('Fare Histogram by Survival')\nplt.xlabel('Fare ($)')\nplt.ylabel('# of Passengers')\nplt.legend()\n\nplt.subplot(235)\nplt.hist(x = [data1[data1['Survived']==1]['Age'], data1[data1['Survived']==0]['Age']], \n         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('Age Histogram by Survival')\nplt.xlabel('Age (Years)')\nplt.ylabel('# of Passengers')\nplt.legend()\n\nplt.subplot(236)\nplt.hist(x = [data1[data1['Survived']==1]['FamilySize'], data1[data1['Survived']==0]['FamilySize']], \n         stacked=True, color = ['g','r'],label = ['Survived','Dead'])\nplt.title('Family Size Histogram by Survival')\nplt.xlabel('Family Size (#)')\nplt.ylabel('# of Passengers')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#graph individual features by survival\nfig, saxis = plt.subplots(2, 3,figsize=(16,12))\n\nsns.barplot(x = 'Embarked', y = 'Survived', data=data1, ax = saxis[0,0])\nsns.barplot(x = 'Pclass', y = 'Survived', order=[1,2,3], data=data1, ax = saxis[0,1])\nsns.barplot(x = 'IsAlone', y = 'Survived', order=[1,0], data=data1, ax = saxis[0,2])\n\nsns.pointplot(x = 'FareBin', y = 'Survived',  data=data1, ax = saxis[1,0])\nsns.pointplot(x = 'AgeBin', y = 'Survived',  data=data1, ax = saxis[1,1])\nsns.pointplot(x = 'FamilySize', y = 'Survived', data=data1, ax = saxis[1,2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#graph distribution of qualitative data: Pclass\n#we know class mattered in survival, now let's compare class and a 2nd feature\nfig, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(14,12))\n\nsns.boxplot(x = 'Pclass', y = 'Fare', hue = 'Survived', data = data1, ax = axis1)\naxis1.set_title('Pclass vs Fare Survival Comparison')\n\nsns.violinplot(x = 'Pclass', y = 'Age', hue = 'Survived', data = data1, split = True, ax = axis2)\naxis2.set_title('Pclass vs Age Survival Comparison')\n\nsns.boxplot(x = 'Pclass', y ='FamilySize', hue = 'Survived', data = data1, ax = axis3)\naxis3.set_title('Pclass vs Family Size Survival Comparison')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation heatmap of dataset\ndef correlation_heatmap(df):\n    _ , ax = plt.subplots(figsize =(14, 12))\n    colormap = sns.diverging_palette(220, 10, as_cmap = True)\n    \n    _ = sns.heatmap(\n        df.corr(), \n        cmap = colormap,\n        square=True, \n        cbar_kws={'shrink':.9 }, \n        ax=ax,\n        annot=True, \n        linewidths=0.1,vmax=1.0, linecolor='white',\n        annot_kws={'fontsize':12 }\n    )\n    \n    plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\ncorrelation_heatmap(data1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Machine Learning Algorithm (MLA) Selection and Initialization\nMLA = [\n    #Ensemble Methods\n    ensemble.AdaBoostClassifier(),\n    ensemble.BaggingClassifier(),\n    ensemble.ExtraTreesClassifier(),\n    ensemble.GradientBoostingClassifier(),\n    ensemble.RandomForestClassifier(),\n\n    #Gaussian Processes\n    gaussian_process.GaussianProcessClassifier(),\n    \n    #GLM\n    linear_model.LogisticRegressionCV(),\n    linear_model.PassiveAggressiveClassifier(),\n    linear_model.RidgeClassifierCV(),\n    linear_model.SGDClassifier(),\n    linear_model.Perceptron(),\n    \n    #Navies Bayes\n    naive_bayes.BernoulliNB(),\n    naive_bayes.GaussianNB(),\n    \n    #Nearest Neighbor\n    neighbors.KNeighborsClassifier(),\n    \n    #SVM\n    svm.SVC(probability=True),\n    svm.NuSVC(probability=True),\n    svm.LinearSVC(),\n    \n    #Trees    \n    tree.DecisionTreeClassifier(),\n    tree.ExtraTreeClassifier(),\n    \n    #Discriminant Analysis\n    discriminant_analysis.LinearDiscriminantAnalysis(),\n    discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n    \n    #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n    XGBClassifier()    \n    ]\n\n\n\n#split dataset in cross-validation with this splitter class: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit\n#note: this is an alternative to train_test_split\ncv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) # run model 10x with 60/30 split intentionally leaving out 10%\n\n#create table to compare MLA metrics\nMLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean', 'MLA Test Accuracy 3*STD' ,'MLA Time']\nMLA_compare = pd.DataFrame(columns = MLA_columns)\n\n#create table to compare MLA predictions\nMLA_predict = data1[Target]\n\n#index through MLA and save performance to table\nrow_index = 0\nfor alg in MLA:\n\n    #set name and parameters\n    MLA_name = alg.__class__.__name__\n    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n    \n    #score model with cross validation: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html\n    #sklearn.model_selection.cross_validate\n    cv_results = model_selection.cross_validate(alg, data1[data1_x_bin], data1[Target], cv  = cv_split, return_train_score=True)\n\n    MLA_compare.loc[row_index, 'MLA Time'] = cv_results['fit_time'].mean()\n    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = cv_results['train_score'].mean()\n    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = cv_results['test_score'].mean()   \n    #if this is a non-bias random sample, then +/-3 standard deviations (std) from the mean, should statistically capture 99.7% of the subsets\n    MLA_compare.loc[row_index, 'MLA Test Accuracy 3*STD'] = cv_results['test_score'].std()*3   #let's know the worst that can happen!\n    \n\n    #save MLA predictions - see section 6 for usage\n    alg.fit(data1[data1_x_bin], data1[Target])\n    MLA_predict[MLA_name] = alg.predict(data1[data1_x_bin])\n    \n    row_index+=1\n\n    \n#print and sort table: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html\nMLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\nMLA_compare\n#MLA_predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Barplot \nsns.barplot(x='MLA Test Accuracy Mean',y='MLA Name', data=MLA_compare, color='m')\n\n#Prettify\nplt.title('Machine Learning Algorithm Accuracy Score \\n')\nplt.xlabel('Accuracy Score (%)')\nplt.ylabel('Algorithm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# base model\n#GridSearchCV\ndtree = tree.DecisionTreeClassifier(random_state=0)\nbase_results = model_selection.cross_validate(dtree,data1[data1_x_bin],data1[Target],cv=cv_split,return_train_score=True)\ndtree.fit(data1[data1_x_bin],data1[Target])\n\nprint(\"BEFORE DT Parameters: \",dtree.get_params())\nprint(\"BEFORE DT Training w/bin score mean: {:.2f}\".format(base_results['train_score'].mean()*100))\nprint(\"BEFORE DT test w/bin score mean: {:.2f}\".format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT test w/bin score 3*std: +/- {:.2f}\".format(base_results['test_score'].std()*300))\nprint('='*30)\n\n# Tune Hyper-parameter\nparam_grid={'criterion':['gini','entropy'], # Scoring methodology; two supported formulas for calculating info gain - default is gini\n           #'splitter':['best','random'], #Splitting methodology; two supported strategies - default is best\n            'max_depth':[2,4,6,8,10,None], #Max depth tree can grow; default is None\n            #'min_sample_split':[2,5,10,0.03,.05], #Minimum subset size BEFORE new split(fraction is % of total); default is 2\n            #'min_sample_leaf';[1,5,10,0.03,.05], #minimum subset size AFTER new split (fraction is % of total); default is 1\n            #'max_features':[None,'auto'], #max features to consider when performing split; default none or all\n            'random_state':[0] #seed or control random number generator\n           }\n# print(list(model_selection.ParameterGrid(param_grid)))\ntune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(),param_grid=param_grid, scoring='roc_auc',cv=cv_split,return_train_score=True)\ntune_model.fit(data1[data1_x_bin],data1[Target])\n\n#print(tune_model.cv_results_.keys())\n#print(tune_model.cv_results_['params'])\nprint('AFTER DT Parameters: ',tune_model.best_params_)\n#print(tune_model.cv_results_['mean_train_model'])\nprint(\"AFTER DT Training w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n#print(tune_model.cv_results_['mean_test_score'])\nprint(\"AFTER DT Test w/bin score mean: {:.2f}\". format(tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\nprint(\"AFTER DT Test w/bin score 3*std: +/- {:.2f}\". format(tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\nprint('='*30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tune model with Feature selction\n# using sklearn.feature_selection.RFECV -- recursive feature elimination(RFE)\n#base model\nprint('BEFORE DT RFE Training Shape Old: ', data1[data1_x_bin].shape) \nprint('BEFORE DT RFE Training Columns Old: ', data1[data1_x_bin].columns.values)\n\nprint(\"BEFORE DT RFE Training w/bin score mean: {:.2f}\". format(base_results['train_score'].mean()*100)) \nprint(\"BEFORE DT RFE Test w/bin score mean: {:.2f}\". format(base_results['test_score'].mean()*100))\nprint(\"BEFORE DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(base_results['test_score'].std()*100*3))\nprint('='*30)\n\n# Feature selection\ndtree_rfe = feature_selection.RFECV(dtree, step=1, scoring='accuracy',cv=cv_split)\ndtree_rfe.fit(data1[data1_x_bin],data1[Target])\n\n#transform x&y to reduced fetures and fit new model\n#alternative: can use pipeline to reduce fit and transform\nX_rfe = data1[data1_x_bin].columns.values[dtree_rfe.get_support()]\nrfe_results = model_selection.cross_validate(dtree, data1[X_rfe], data1[Target],cv=cv_split,return_train_score=True)\n\n#print(dtree_rfe.grid_scores_)\nprint('AFTER DT RFE Training Shape New: ', data1[X_rfe].shape) \nprint('AFTER DT RFE Training Columns New: ', X_rfe)\n\nprint(\"AFTER DT RFE Training w/bin score mean: {:.2f}\". format(rfe_results['train_score'].mean()*100)) \nprint(\"AFTER DT RFE Test w/bin score mean: {:.2f}\". format(rfe_results['test_score'].mean()*100))\nprint(\"AFTER DT RFE Test w/bin score 3*std: +/- {:.2f}\". format(rfe_results['test_score'].std()*100*3))\nprint('='*30)\n\n#tune rfe model\nrfe_tune_model = model_selection.GridSearchCV(tree.DecisionTreeClassifier(),param_grid=param_grid,scoring='roc_auc',cv=cv_split,return_train_score=True)\nrfe_tune_model.fit(data1[X_rfe],data1[Target])\n#print(rfe_tune_model.cv_results_.keys())\n#print(rfe_tune_model.cv_results_['params'])\nprint('AFTER DT RFE Tuned Parameters: ', rfe_tune_model.best_params_)\n#print(rfe_tune_model.cv_results_['mean_train_score'])\nprint(\"AFTER DT RFE Tuned Training w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_train_score'][tune_model.best_index_]*100)) \n#print(rfe_tune_model.cv_results_['mean_test_score'])\nprint(\"AFTER DT RFE Tuned Test w/bin score mean: {:.2f}\". format(rfe_tune_model.cv_results_['mean_test_score'][tune_model.best_index_]*100))\nprint(\"AFTER DT RFE Tuned Test w/bin score 3*std: +/- {:.2f}\". format(rfe_tune_model.cv_results_['std_test_score'][tune_model.best_index_]*100*3))\nprint('='*30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Graph MLA version of Decision tree\nimport graphviz\ndot_data = tree.export_graphviz(dtree, out_file=None,feature_names=data1_x_bin,class_names=True,filled=True,rounded=True)\ngraph = graphviz.Source(dot_data)\ngraph","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Validate and Implement\n#compare algorithm predictions with each other, where 1 = exactly similar and 0 = exactly opposite\n#there are some 1's, but enough blues and light reds to create a \"super algorithm\" by combining them\ncorrelation_heatmap(MLA_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#why choose one model, when you can pick them all with voting classifier\n#http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html\n#removed models w/o attribute 'predict_proba' required for vote classifier and models with a 1.0 correlation to another model\nvote_est =[\n    #Ensemble Methods\n    ('ada',ensemble.AdaBoostClassifier()),\n    ('bc',ensemble.BaggingClassifier()),\n    ('etc',ensemble.ExtraTreesClassifier()),\n    ('gbc',ensemble.GradientBoostingClassifier()),\n    ('rfc',ensemble.RandomForestClassifier()),\n    \n    #Gaussian Processes\n    ('gpc',gaussian_process.GaussianProcessClassifier()),\n    \n    #GLM\n    ('lr',linear_model.LogisticRegressionCV()),\n    \n    #Navies Bayes\n    ('bnb',naive_bayes.BernoulliNB()),\n    ('gnb',naive_bayes.GaussianNB()),\n    \n    #Nearest Neighbor\n    ('knn',neighbors.KNeighborsClassifier()),\n    \n    #SVM\n    ('svc',svm.SVC(probability=True)),\n    \n    #xgboost\n    ('xgb',XGBClassifier())\n]\n\n#Hard Vote or majority rules\nvote_hard = ensemble.VotingClassifier(estimators=vote_est, voting='hard')\nvote_hard_cv = model_selection.cross_validate(vote_hard,data1[data1_x_bin],data1[Target],cv = cv_split,return_train_score=True)\nprint(\"Hard Voting Training w/bin score mean: {:.2f}\". format(vote_hard_cv['train_score'].mean()*100)) \nprint(\"Hard Voting Test w/bin score mean: {:.2f}\". format(vote_hard_cv['test_score'].mean()*100))\nprint(\"Hard Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_hard_cv['test_score'].std()*100*3))\nprint('='*30)\n\n#Soft vote or weighted prob\nvote_soft = ensemble.VotingClassifier(estimators=vote_est,voting='soft')\nvote_soft_cv = model_selection.cross_validate(vote_soft, data1[data1_x_bin],data1[Target],cv=cv_split,return_train_score=True)\nvote_soft.fit(data1[data1_x_bin],data1[Target])\n\nprint(\"Soft Voting Training w/bin score mean: {:.2f}\". format(vote_soft_cv['train_score'].mean()*100)) \nprint(\"Soft Voting Test w/bin score mean: {:.2f}\". format(vote_soft_cv['test_score'].mean()*100))\nprint(\"Soft Voting Test w/bin score 3*std: +/- {:.2f}\". format(vote_soft_cv['test_score'].std()*100*3))\nprint('='*30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#WARNING: Running is very computational intensive and time expensive.\n#Hyperparameter Tune with GridSearchCV: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\ngrid_n_estimator = [10, 50, 100, 300]\ngrid_ratio = [.1, .25, .5, .75, 1.0]\ngrid_learn = [.01, .03, .05, .1, .25]\ngrid_max_depth = [2, 4, 6, 8, 10, None]\ngrid_min_samples = [5, 10, .03, .05, .10]\ngrid_criterion = ['gini', 'entropy']\ngrid_bool = [True, False]\ngrid_seed = [0]\n\ngrid_param=[\n    [{\n      #AdaBoostClassifier\n        'n_estimators':grid_n_estimator, #default=50\n        'learning_rate':grid_learn, #default=1\n        #'algorithm':['SAMME','SAMME.R'], #default='SAMME.R'\n        'random_state':grid_seed\n    }],\n    [{\n        #BaggingClassifier\n        'n_estimators':grid_n_estimator, #default=10\n        'max_samples': grid_ratio, #default=1.0\n        'random_state': grid_seed\n    }],\n    \n    [{\n        #ExtraTreesClassifier\n        'n_estimators': grid_n_estimator, #default=10\n        'criterion': grid_criterion, #default=”gini”\n        'max_depth': grid_max_depth, #default=None\n        'random_state': grid_seed\n    }],\n    \n    [{\n        #GradientBoostingClassifier\n        #'loss': ['deviance', 'exponential'], #default=’deviance’\n            'learning_rate': [.05], #default=0.1 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n            'n_estimators': [300], #default=100 -- 12/31/17 set to reduce runtime -- The best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 264.45 seconds.\n            #'criterion': ['friedman_mse', 'mse', 'mae'], #default=”friedman_mse”\n            'max_depth': grid_max_depth, #default=3   \n            'random_state': grid_seed\n    }],\n    \n    [{\n        #RandomForestClassifier\n        'n_estimators': grid_n_estimator, #default=10\n            'criterion': grid_criterion, #default=”gini”\n            'max_depth': grid_max_depth, #default=None\n            'oob_score': [True], #default=False -- 12/31/17 set to reduce runtime -- The best parameter for RandomForestClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 100, 'oob_score': True, 'random_state': 0} with a runtime of 146.35 seconds.\n            'random_state': grid_seed\n    }],\n    \n    [{    \n            #GaussianProcessClassifier\n            'max_iter_predict': grid_n_estimator, #default: 100\n            'random_state': grid_seed\n    }],\n        \n    \n    [{\n            #LogisticRegressionCV \n            'fit_intercept': grid_bool, #default: True\n            #'penalty': ['l1','l2'],\n            'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], #default: lbfgs\n            'random_state': grid_seed\n    }],\n            \n    \n    [{\n            #BernoulliNB \n            'alpha': grid_ratio, #default: 1.0\n    }],\n    \n            #GaussianNB - \n             [{}],\n    \n    [{\n            #KNeighborsClassifier\n            'n_neighbors': [1,2,3,4,5,6,7], #default: 5\n            'weights': ['uniform', 'distance'], #default = ‘uniform’\n            'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n    }],\n            \n    \n    [{\n            #SVC \n            #http://blog.hackerearth.com/simple-tutorial-svm-parameter-tuning-python-r\n            #'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n            'C': [1,2,3,4,5], #default=1.0\n            'gamma': grid_ratio, #edfault: auto\n            'decision_function_shape': ['ovo', 'ovr'], #default:ovr\n            'probability': [True],\n            'random_state': grid_seed\n    }],\n\n    [{\n      #XGBClassifier\n      'learning_rate': grid_learn, #default: .3\n      'max_depth': [1,2,4,6,8,10], #default 2\n      'n_estimators': grid_n_estimator, \n      'seed': grid_seed  \n    }]   \n]\n\nstart_total = time.perf_counter()\nfor clf, param in zip(vote_est, grid_param):\n    start = time.perf_counter()\n    best_search = model_selection.GridSearchCV(estimator=clf[1], param_grid=param,cv=cv_split, scoring='roc_auc')\n    best_search.fit(data1[data1_x_bin], data1[Target])\n    run = time.perf_counter()-start\n    \n    best_param = best_search.best_params_\n    print('The best parameter for {} is {} with a runtime of {:.2f} seconds.'.format(clf[1].__class__.__name__, best_param, run))\n    clf[1].set_params(**best_param)\n    \nrun_total = time.perf_counter()-start_total\nprint('Total optimization time was {:.2f} minutes'.format(run_total/60))\n\nprint('='*30)","execution_count":77,"outputs":[{"output_type":"stream","text":"The best parameter for AdaBoostClassifier is {'learning_rate': 0.25, 'n_estimators': 100, 'random_state': 0} with a runtime of 42.76 seconds.\nThe best parameter for BaggingClassifier is {'max_samples': 0.25, 'n_estimators': 300, 'random_state': 0} with a runtime of 43.26 seconds.\nThe best parameter for ExtraTreesClassifier is {'criterion': 'entropy', 'max_depth': 6, 'n_estimators': 300, 'random_state': 0} with a runtime of 75.77 seconds.\nThe best parameter for GradientBoostingClassifier is {'learning_rate': 0.05, 'max_depth': 2, 'n_estimators': 300, 'random_state': 0} with a runtime of 44.79 seconds.\nThe best parameter for RandomForestClassifier is {'criterion': 'gini', 'max_depth': 6, 'n_estimators': 50, 'oob_score': True, 'random_state': 0} with a runtime of 114.80 seconds.\nThe best parameter for GaussianProcessClassifier is {'max_iter_predict': 10, 'random_state': 0} with a runtime of 8.38 seconds.\nThe best parameter for LogisticRegressionCV is {'fit_intercept': True, 'random_state': 0, 'solver': 'saga'} with a runtime of 9.36 seconds.\nThe best parameter for BernoulliNB is {'alpha': 0.1} with a runtime of 0.34 seconds.\nThe best parameter for GaussianNB is {} with a runtime of 0.07 seconds.\nThe best parameter for KNeighborsClassifier is {'algorithm': 'brute', 'n_neighbors': 7, 'weights': 'uniform'} with a runtime of 5.67 seconds.\nThe best parameter for SVC is {'C': 2, 'decision_function_shape': 'ovo', 'gamma': 0.25, 'probability': True, 'random_state': 0} with a runtime of 29.55 seconds.\nThe best parameter for XGBClassifier is {'learning_rate': 0.01, 'max_depth': 4, 'n_estimators': 300, 'seed': 0} with a runtime of 92.38 seconds.\nTotal optimization time was 7.79 minutes\n==============================\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hard vote or majority rules w/Tuned Hyperparameters\ngrid_hard = ensemble.VotingClassifier(estimators=vote_est, voting='hard')\ngrid_hard_cv = model_selection.cross_validate(grid_hard, data1[data1_x_bin], data1[Target],cv = cv_split,return_train_score=True)\ngrid_hard.fit(data1[data1_x_bin], data1[Target])\n\nprint(\"Hard Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_hard_cv['train_score'].mean()*100)) \nprint(\"Hard Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_hard_cv['test_score'].mean()*100))\nprint(\"Hard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_hard_cv['test_score'].std()*100*3))\nprint('='*30)\n\n#soft vote or weighted prob w/Tuned Hyperparameters\ngrid_soft = ensemble.VotingClassifier(estimators=vote_est, voting='soft')\ngrid_soft_cv = model_selection.cross_validate(grid_soft, data1[data1_x_bin], data1[Target],cv=cv_split,return_train_score=True)\ngrid_soft.fit(data1[data1_x_bin], data1[Target])\nprint(\"Soft Voting w/Tuned Hyperparameters Training w/bin score mean: {:.2f}\". format(grid_soft_cv['train_score'].mean()*100)) \nprint(\"Soft Voting w/Tuned Hyperparameters Test w/bin score mean: {:.2f}\". format(grid_soft_cv['test_score'].mean()*100))\nprint(\"Soft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- {:.2f}\". format(grid_soft_cv['test_score'].std()*100*3))\nprint('='*30)","execution_count":78,"outputs":[{"output_type":"stream","text":"Hard Voting w/Tuned Hyperparameters Training w/bin score mean: 85.54\nHard Voting w/Tuned Hyperparameters Test w/bin score mean: 82.24\nHard Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 4.48\n==============================\nSoft Voting w/Tuned Hyperparameters Training w/bin score mean: 85.39\nSoft Voting w/Tuned Hyperparameters Test w/bin score mean: 82.28\nSoft Voting w/Tuned Hyperparameters Test w/bin score 3*std: +/- 5.35\n==============================\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prepare data for modeling\nprint(data_val.info())\nprint('='*30)\ndata_val['Survived']=grid_hard.predict(data_val[data1_x_bin])\nsubmit = data_val[['PassengerId','Survived']]\nsubmit.to_csv('../working/submit.csv',index=False)\nprint('Validation Data Distribution: \\n',data_val['Survived'].value_counts(normalize=True))\nsubmit.sample(10)","execution_count":81,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 22 columns):\nPassengerId      418 non-null int64\nPclass           418 non-null int64\nName             418 non-null object\nSex              418 non-null object\nAge              418 non-null float64\nSibSp            418 non-null int64\nParch            418 non-null int64\nTicket           418 non-null object\nFare             418 non-null float64\nCabin            91 non-null object\nEmbarked         418 non-null object\nFamilySize       418 non-null int64\nIsAlone          418 non-null int64\nTitle            418 non-null object\nFareBin          418 non-null category\nAgeBin           418 non-null category\nSex_Code         418 non-null int64\nEmbarked_Code    418 non-null int64\nTitle_Code       418 non-null int64\nAgeBin_Code      418 non-null int64\nFareBin_Code     418 non-null int64\nSurvived         418 non-null int64\ndtypes: category(2), float64(2), int64(12), object(6)\nmemory usage: 66.7+ KB\nNone\n==============================\nValidation Data Distribution: \n 0    0.641148\n1    0.358852\nName: Survived, dtype: float64\n","name":"stdout"},{"output_type":"execute_result","execution_count":81,"data":{"text/plain":"     PassengerId  Survived\n58           950         0\n317         1209         0\n75           967         0\n209         1101         0\n123         1015         0\n166         1058         0\n36           928         1\n254         1146         0\n238         1130         1\n43           935         1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>58</th>\n      <td>950</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>317</th>\n      <td>1209</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>967</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>209</th>\n      <td>1101</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>123</th>\n      <td>1015</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>1058</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>928</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>254</th>\n      <td>1146</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>238</th>\n      <td>1130</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>935</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data1.columns)\n# data1[data1_x_bin]\ndata1_x_bin","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}